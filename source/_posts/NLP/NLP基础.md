---
author: chong
title:  自然语言处理-NLP基础
data: 2022-01-10 12:00:00
categories: NLP
---



# 自然语言处理

## 一、NLP基本概念

### 1.1、自然语言处理 - NLP

自然语言处理（NLP）就是在机器语言和人类语言之间沟通的桥梁，以实现人机交流的目的。

**难点：**没有规律、自由组合复杂的语言表达、全新的表达方式、知识依赖、基于环境和上下文
				多样性、歧义性、鲁棒性、知识依赖、上下文

**应用：**情感分析、聊天机器人、语音识别、机器翻译

**预料预处理（中）：**中文分词(Chinese Word Segmentation)`->`词性标注(Parts of Speech)`->`命名实体识别(NER)`->`去除停用词

**预料预处理（英）：**分词(tokenization)`->`词干提取(stemming)`->`词形还原(lemmatization)`->`词性标注(pos tags)`->`命名实体识别(ner->`分块(chunking)

![image-20231225113255562](img/image-20231225113255562.png)

### 1.1、自然语言理解 - NLU | NLI

自然语言理解就是希望机器像人一样，具备正常人的语言理解能力

 **NLU**至今还远不如人类，有很多难点（语言的多样性、歧义性、鲁棒性、知识依赖、上下文）。

1. 基于规则的方法
2. 基于统计的方法
3. 基于深度学习的方法



### 1.2、自然语言生成 - NLG

**NLG**是为了跨越人类和机器之间的沟通鸿沟，将非语言格式的数据转换成人类可以理解的语言格式，如文章、报告等。

**NLG有两种方式：**`text-to-text`：⽂文本到语⾔言的⽣生成；`data-to-text` ：数据到语⾔言的⽣生成

**NLG 的6个步骤：**

1. 内容确定 – Content Determination
2. 文本结构 – Text Structuring
3. 句子聚合 – Sentence Aggregation
4. 语法化 – Lexicalisation
5. 参考表达式生成 – Referring Expression Generation|REG
6. 语言实现 – Linguistic Realisation



## 二、基础扩展

### 2.1、分词 - TOKENIZATION

分词，将句子、段落、文章这种长文本，分解为以字词为单位的数据结构，方便后续的处理分析工作。

文本【非结构化数据】`=>>`易于理解的【结构化数据】`=>>`【数学问题】

词是表达完整含义的最小单位，是一个比较适合的粒度

**中英文分词区别：**分词方式不同，中文更难；英文单词有多种形态，需要词性还原和词干提取；中文分词需要考虑粒度问题。

**中文分词的3大难点：**没有统一的标准；歧义词如何切分；新词的识别。

**3个典型的分词方式：**基于词典匹配；基于统计；基于深度学习。

### 2.2、词干提取 - STEMMING && 词形还原 - LEMMATISATION

词干提取时英文预料预处理的一个步骤，预料预处理是NLP的第一步。

|                             图解                             | 文字注释                                                     |
| :----------------------------------------------------------: | :----------------------------------------------------------- |
| <img src="img/image-20231225134313816.png" style="zoom: 25%;" > | 词干提取时英文预料预处理的一个步骤，预料预处理是NLP的第一步。 |
| <img src="img/image-20231225135205727.png" alt="image-20231225135205727" style="zoom:25%;" /> | **1、词干提取 - STEMMING**<br />去除单词的前后缀得到词根的过程；<br />前后缀：【名词复数】【进行式】【过去分词】...<br /> |
| <img src="img/image-20231225135158099.png" alt="image-20231225135158099" style="zoom:25%;" /> | **2、词形还原 - Lemmatisation**<br />基于词典，将单词的复杂形态转变为最基础的形态 |

**相似点：**目标一致、结果部分分叉、主流实现方法类似、应用领域相似

**不同点：**原理不同、词形还原更复杂、实现侧重点不同、应用领域侧重点不同、呈现结果不同

**主流词干提取算法：**Porter、Snowball、Lancaster

### 2.3、词性标注 - PART OF SPEECH

词性是以词的特点作为划分词类的依据。

词类是一个语言学术语，是一种语言中词的语法分类，是以语法特征（包括句法功能和形态变化）为主要依据、兼顾词汇意义对此进行划分的结果。在一个语言中，众多具有相同句法功能、能在同样的组合位置中出现的词，聚合在一起的范畴。

**常见方法：**基于规则、基于统计、基于规则+统计、基于深度学习

词性标注工具：Jieba、SnowNLP、THULAC、StanfordCoreNLP、HanLP、NLTK、SpaCy

### 2.4、命名实体识别 - NER

命名实体识别，识别文本中具有特定意义的实体，主要包括人名、地名、机构名、专有名词等。

![image-20231225141238507](img/image-20231225141238507.png)
